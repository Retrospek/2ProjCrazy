{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Clustering***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")  # Loading Google's Word2Vec model (300-dimensional vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Retrieve word vectors from Word2Vec model\n",
    "word_vectors = np.array([model[word] if word in model else np.random.rand(300) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided word data\n",
    "data = [\n",
    "    [\n",
    "        {\"words\": [\"BENT\", \"GNARLY\", \"TWISTED\", \"WARPED\"], \"category\": \"CONTORTED\"},\n",
    "        {\"words\": [\"LICK\", \"OUNCE\", \"SHRED\", \"TRACE\"], \"category\": \"SMALLEST AMOUNT\"},\n",
    "        {\"words\": [\"EXPONENT\", \"POWER\", \"RADICAL\", \"ROOT\"], \"category\": \"ALGEBRA TERMS\"},\n",
    "        {\"words\": [\"BATH\", \"POWDER\", \"REST\", \"THRONE\"], \"category\": \"WORDS BEFORE “ROOM” TO MEAN LAVATORY\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"words\": [\"ANTIC\", \"CAPER\", \"EXPLOIT\", \"STUNT\"], \"category\": \"ESCAPADE\"},\n",
    "        {\"words\": [\"DILL\", \"KOSHER\", \"SOUR\", \"SWEET\"], \"category\": \"KINDS OF PICKLES\"},\n",
    "        {\"words\": [\"ADULT\", \"BLUE\", \"SPICY\", \"SUGGESTIVE\"], \"category\": \"RISQUÉ\"},\n",
    "        {\"words\": [\"CHEESE\", \"CORD\", \"DECK\", \"MUSTARD\"], \"category\": \"CUT THE ___\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"words\": [\"HASH\", \"SALAD\", \"SCRAMBLE\", \"STEW\"], \"category\": \"FOOD-RELATED JUMBLES\"},\n",
    "        {\"words\": [\"CHARACTER\", \"IMAGE\", \"NAME\", \"REPUTATION\"], \"category\": \"PUBLIC STANDING\"},\n",
    "        {\"words\": [\"ARTIST\", \"MEDIUM\", \"TITLE\", \"YEAR\"], \"category\": \"INFO ON A MUSEUM PLACARD\"},\n",
    "        {\"words\": [\"DIAL\", \"EGADS\", \"MONTE\", \"YOGA\"], \"category\": \"ANAGRAMS OF FAMOUS PAINTERS\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"words\": [\"PAUSE\", \"PLAY\", \"RECORD\", \"STOP\"], \"category\": \"DVR BUTTONS\"},\n",
    "        {\"words\": [\"DIFFERENT\", \"NEW\", \"NOVEL\", \"ORIGINAL\"], \"category\": \"GROUNDBREAKING\"},\n",
    "        {\"words\": [\"CORRESPOND\", \"MESSAGE\", \"TEXT\", \"WRITE\"], \"category\": \"COMMUNICATE THROUGH WRITING\"},\n",
    "        {\"words\": [\"BIPED\", \"FURNITURE\", \"POEM\", \"YARDSTICK\"], \"category\": \"THINGS WITH FEET\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"words\": [\"CATERPILLAR\", \"FLEECE\", \"PEACH\", \"PIPE CLEANER\"], \"category\": \"THINGS THAT ARE FUZZY\"},\n",
    "        {\"words\": [\"CLAM\", \"EGG\", \"NUT\", \"TURTLE\"], \"category\": \"THINGS WITH SHELLS\"},\n",
    "        {\"words\": [\"DONKEY\", \"DRAGON\", \"OGRE\", \"PRINCESS\"], \"category\": \"FIGURES IN “SHREK”\"},\n",
    "        {\"words\": [\"CARPET\", \"KINGDOM\", \"MARKER\", \"MUSHROOM\"], \"category\": \"MAGIC ___\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"words\": [\"FURNISH\", \"OUTFIT\", \"PROVISION\", \"STOCK\"], \"category\": \"EQUIP\"},\n",
    "        {\"words\": [\"BEING\", \"CHARACTER\", \"EGO\", \"SELF\"], \"category\": \"INDIVIDUALITY\"},\n",
    "        {\"words\": [\"CHEST\", \"CONSOLE\", \"VANITY\", \"WARDROBE\"], \"category\": \"FURNITURE\"},\n",
    "        {\"words\": [\"CANT\", \"ID\", \"SHELL\", \"WERE\"], \"category\": \"WORDS WITH APOSTROPHES REMOVED\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"words\": [\"MOVING\", \"SWEET\", \"TENDER\", \"TOUCHING\"], \"category\": \"HEARTWARMING\"},\n",
    "        {\"words\": [\"FEELING\", \"HUNCH\", \"IMPRESSION\", \"SENSE\"], \"category\": \"SNEAKING SUSPICION\"},\n",
    "        {\"words\": [\"HEARING\", \"INQUIRY\", \"PROCEEDING\", \"TRIAL\"], \"category\": \"LEGAL SESSION\"},\n",
    "        {\"words\": [\"CHAIR\", \"LISTENING\", \"MONEY\", \"STREET\"], \"category\": \"EASY ___\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"words\": [\"COUNTER\", \"FRIDGE\", \"RANGE\", \"SINK\"], \"category\": \"SEEN IN A KITCHEN\"},\n",
    "        {\"words\": [\"BOARD\", \"CABINET\", \"COUNCIL\", \"PANEL\"], \"category\": \"GROUP OF ADVISORS\"},\n",
    "        {\"words\": [\"BOAT\", \"CRUNCH\", \"MOUNTAIN CLIMBER\", \"PLANK\"], \"category\": \"CORE EXERCISES\"},\n",
    "        {\"words\": [\"CHANDELIER\", \"DROP\", \"HOOP\", \"STUD\"], \"category\": \"KINDS OF EARRINGS\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"words\": [\"CRAWL\", \"CREEP\", \"DRAG\", \"INCH\"], \"category\": \"PROGRESS SLOWLY\"},\n",
    "        {\"words\": [\"BOTTLE\", \"CAN\", \"DRAFT\", \"TAP\"], \"category\": \"WAYS TO ORDER A BEER\"},\n",
    "        {\"words\": [\"BALL\", \"CURL\", \"DOODLE\", \"PUFF\"], \"category\": \"CHEESY CORN SNACK UNIT\"},\n",
    "        {\"words\": [\"BUTTERFLY\", \"DOMINO\", \"HALO\", \"PLACEBO\"], \"category\": \"___ EFFECT\"}\n",
    "    ],\n",
    "    [\n",
    "        {\"words\": [\"DARLING\", \"LOVE\", \"PUMPKIN\", \"TREASURE\"], \"category\": \"TERMS OF ENDEARMENT\"},\n",
    "        {\"words\": [\"BAT\", \"BLINK\", \"FLUTTER\", \"WINK\"], \"category\": \"THINGS YOU CAN DO WITH YOUR EYELIDS\"},\n",
    "        {\"words\": [\"DIABLO\", \"MUSTANG\", \"SPIDER\", \"VIPER\"], \"category\": \"SPORTS CARS\"},\n",
    "        {\"words\": [\"EGG\", \"JOB\", \"SCAVENGER\", \"WITCH\"], \"category\": \"___ HUNT\"}\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m word_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([model\u001b[38;5;241m.\u001b[39mwv[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m all_words])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity between all pairs of words\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m(word_vectors)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Function to find the 4 most similar words to each word\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_most_similar_words\u001b[39m(similarity_matrix, words, num_similar\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "# Flatten the list of words\n",
    "all_words = []\n",
    "for group in data:\n",
    "    for entry in group:\n",
    "        all_words.extend(entry[\"words\"])\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec([all_words], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get the word embeddings for each word\n",
    "word_vectors = np.array([model.wv[word] for word in all_words])\n",
    "\n",
    "# Compute cosine similarity between all pairs of words\n",
    "similarity_matrix = cosine_similarity(word_vectors)\n",
    "\n",
    "# Function to find the 4 most similar words to each word\n",
    "def find_most_similar_words(similarity_matrix, words, num_similar=4):\n",
    "    for idx, word in enumerate(words):\n",
    "        # Get the indices of the most similar words (excluding the word itself)\n",
    "        similar_indices = np.argsort(similarity_matrix[idx])[::-1][1:num_similar+1]\n",
    "        similar_words = [words[i] for i in similar_indices]\n",
    "        print(f\"Word: {word}, Most similar words: {similar_words}\")\n",
    "\n",
    "# Find the most similar words\n",
    "find_most_similar_words(similarity_matrix, all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
